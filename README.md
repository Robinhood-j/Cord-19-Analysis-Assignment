# CORD-19 Data Analysis Project ğŸ¦ 

A comprehensive data analysis and visualization project exploring COVID-19 research papers from the CORD-19 dataset.

## ğŸ“Š Project Overview

This project analyzes the CORD-19 dataset to uncover insights about COVID-19 research publications, including:
- Publication trends over time
- Top journals and sources
- Research paper characteristics
- Interactive data exploration

## ğŸš€ Features

### Data Analysis
- **Comprehensive EDA**: Complete exploratory data analysis with statistical insights
- **Data Cleaning**: Robust data preprocessing and cleaning pipeline
- **Visualization Suite**: Multiple chart types including trends, distributions, and correlations
- **Word Analysis**: Title word frequency analysis and word clouds

### Interactive Web Application
- **Real-time Filtering**: Dynamic data filtering by year, journal, source, and content type
- **Interactive Charts**: Plotly-powered visualizations with hover effects
- **Data Export**: Download filtered datasets as CSV
- **Responsive Design**: Mobile-friendly interface

## ğŸ› ï¸ Technologies Used

- **Python 3.7+**
- **pandas**: Data manipulation and analysis
- **matplotlib/seaborn**: Static visualizations
- **plotly**: Interactive charts
- **streamlit**: Web application framework
- **wordcloud**: Text visualization
- **numpy**: Numerical computations

## ğŸ“ Project Structure

```
CORD-19-Analysis/
â”œâ”€â”€ cord19_analysis.py          # Main analysis script
â”œâ”€â”€ streamlit_app.py           # Streamlit web application
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ data/                      # Data directory
â”‚   â””â”€â”€ metadata.csv          # CORD-19 metadata (download separately)
â””â”€â”€ results/                   # Generated outputs
    â”œâ”€â”€ cord19_cleaned.csv    # Cleaned dataset
    â””â”€â”€ visualizations/       # Saved plots
```

## âš¡ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/CORD-19-Analysis.git
cd CORD-19-Analysis
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Download Data (Optional)
- Download `metadata.csv` from [Kaggle CORD-19 Dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)
- Place it in the project root directory
- Or run with sample data (automatically generated)

### 4. Run Analysis
```bash
python cord19_analysis.py
```

### 5. Launch Web App
```bash
streamlit run streamlit_app.py
```

## ğŸ“Š Analysis Results

### Key Findings
- **Total Papers Analyzed**: 1,000+ research papers
- **Date Range**: 2019-2023 
- **Peak Publication Year**: 2021 (pandemic response)
- **Top Journals**: Nature, Science, Cell, The Lancet
- **Research Focus**: 80%+ COVID-related papers

### Visualizations Generated
1. **Publication Trends**: Time series showing research output over time
2. **Journal Analysis**: Top publishing journals and their contributions
3. **Source Distribution**: Breakdown by publication sources (PMC, PubMed, etc.)
4. **Content Analysis**: Abstract length distributions and word frequency
5. **Word Clouds**: Visual representation of common research themes

## ğŸŒ Web Application Features

### Interactive Dashboard
- **Real-time Filtering**: Filter by year range, journal, source, and research type
- **Dynamic Visualizations**: Charts update based on selected filters
- **Data Summary**: Key metrics and statistics display
- **Sample Data View**: Browse and download filtered datasets

### Navigation Tabs
1. **ğŸ“ˆ Trends**: Publication patterns and temporal analysis
2. **ğŸ“Š Distributions**: Journal and source breakdowns
3. **ğŸ” Analysis**: Advanced analytics and correlations
4. **ğŸ“„ Data Sample**: Raw data exploration and export

## ğŸ’» Usage Examples

### Basic Analysis
```python
# Load and analyze data
from cord19_analysis import load_and_explore_data, clean_and_prepare_data

# Load dataset
df = load_and_explore_data('metadata.csv')

# Clean and prepare
df_clean = clean_and_prepare_data(df)

# Perform analysis
perform_data_analysis(df_clean)
```

### Streamlit App Customization
```python
# Run with specific configurations
streamlit run streamlit_app.py --server.port 8501
```

## ğŸ“‹ Assignment Completion

### âœ… Completed Tasks

**Part 1: Data Loading and Exploration**
- [x] Dataset loading with error handling
- [x] Basic data exploration and structure analysis
- [x] Missing values identification and handling
- [x] Data type validation and conversion

**Part 2: Data Cleaning and Preparation**
- [x] Comprehensive data cleaning pipeline
- [x] Date parsing and feature extraction
- [x] New feature creation (word counts, COVID classification)
- [x] Data validation and filtering

**Part 3: Data Analysis and Visualization**
- [x] Statistical analysis and insights generation
- [x] Multiple visualization types (line, bar, histogram, scatter, pie)
- [x] Advanced analytics (correlations, trends, distributions)
- [x] Word cloud generation and text analysis

**Part 4: Streamlit Application**
- [x] Interactive web application with modern UI
- [x] Real-time filtering and dynamic updates
- [x] Multiple visualization tabs and layouts
- [x] Data export functionality

**Part 5: Documentation and Deployment**
- [x] Comprehensive code documentation
- [x] README with setup instructions
- [x] Requirements file for dependencies
- [x] GitHub repository structure

## ğŸ¯ Learning Outcomes Achieved

- âœ… **Real-world Data Handling**: Experience with messy, large-scale datasets
- âœ… **Data Cleaning Mastery**: Robust preprocessing and validation techniques
- âœ… **Visualization Skills**: Multiple chart types with professional styling
- âœ… **Web Development**: Interactive dashboard creation with Streamlit
- âœ… **Project Management**: Complete end-to-end data science project

## ğŸš€ Advanced Features

### Performance Optimizations
- Data caching for faster app performance
- Efficient filtering algorithms
- Lazy loading for large datasets

### Enhanced Analytics
- Statistical correlation analysis
- Time series trend analysis
- Text mining and NLP features
- Custom metric calculations

### User Experience
- Responsive design for all devices
- Interactive tooltips and help text
- Professional styling with custom CSS
- Error handling and user feedback

## ğŸ”§ Troubleshooting

### Common Issues

**Data Loading Problems**
```bash
# If metadata.csv is missing, the app generates sample data
# Download the real dataset from Kaggle for full analysis
```

**Package Installation Issues**
```bash
# Update pip and try again
pip install --upgrade pip
pip install -r requirements.txt
```

**Streamlit Port Issues**
```bash
# Use different port if 8501 is busy
streamlit run streamlit_app.py --server.port 8502
```

## ğŸ“ˆ Future Enhancements

- [ ] Machine learning models for research classification
- [ ] Advanced NLP analysis (sentiment, topic modeling)
- [ ] Database integration for larger datasets
- [ ] Real-time data updates from research APIs
- [ ] Collaborative features for multiple users

## ğŸ‘¨â€ğŸ’» Author

**Robinhood Waweru**
- GitHub: [Robinhood-j](https://github.com/Robinhood-j)
- Email: robinhoodwaweru18@gmail.com

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Allen Institute for AI** for the CORD-19 dataset
- **Streamlit Team** for the excellent web framework
- **Plotly Team** for interactive visualizations
- **Course Instructors** for guidance and support

## ğŸ“ Support

For questions or issues:
1. Check the troubleshooting section above
2. Open an issue on GitHub
3. Contact the course instructors
4. Refer to the official documentation

---

**â­ If you found this project helpful, please give it a star on GitHub!**